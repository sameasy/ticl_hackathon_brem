{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "torch.manual_seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "class ClusData(Data):\n",
    "    def __init__(self, edge_index_clus=None, x_clus=None, edge_index_nodex=None, x_nodex=None):\n",
    "        super().__init__()\n",
    "        self.edge_index_clus = edge_index_clus\n",
    "        self.x_clus = x_clus\n",
    "        self.edge_index_nodex = edge_index_nodex\n",
    "        self.x_nodex = x_nodex\n",
    "        \n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index_clus':\n",
    "            return self.x_clus.size(0)\n",
    "        if key == 'edge_index_nodex':\n",
    "            return self.x_nodex.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import electron datasets\n",
    "import glob\n",
    "raw_dir=\"/grid_mnt/data__data.polcms/cms/sghosh/hackathon/graphsv2_thr0p2phi0p2_clusprops/\"\n",
    "#raw_dir='/data_CMS/cms/sghosh/elecgraphs/V1condor/'\n",
    "fnamelist = [filepath for filepath in glob.glob(raw_dir+'data*.pt')]\n",
    "data_list_ele = []\n",
    "etav = []\n",
    "ctr = 0\n",
    "for i in tqdm(fnamelist):\n",
    "    idx = torch.load(i)\n",
    "    #print(idx.x.shape[0])\n",
    "    #idx.x = idx.clusx\n",
    "    '''print(idx.keys)\n",
    "    break'''\n",
    "    \n",
    "    if idx.nodex.shape[0] < 3:\n",
    "        continue\n",
    "    if not(np.any(idx.nodelabel.numpy())):  ### remove where there are no eles matched\n",
    "        continue\n",
    "        \n",
    "    data = ClusData(x_clus = idx.clusx, x_nodex = idx.nodex,edge_index_nodex=idx.edgeidx.long())    \n",
    "    data.edgelabel = idx.edgelabel\n",
    "    data.clusidx = idx.clusidx\n",
    "    #idx.edge_index = idx.edgeidx.long()\n",
    "    #idx.edgeidx = []\n",
    "    #idx.clusidx = torch.tensor(torch.unsqueeze(idx.clusidx,dim=1),dtype=torch.int32)\n",
    "    data_list_ele.append(data)\n",
    "    #ctr += 1\n",
    "    #if ctr > 200:\n",
    "    #    break\n",
    "    #data_list.append(torch.load(i))\n",
    "    \n",
    "\n",
    "#data_list=[x for x in data_list if (x.y<100.)]   \n",
    "print((data_list_ele[0].x))\n",
    "#print(data_list_pho[0].z)\n",
    "print(len(data_list_ele))\n",
    "totalevele = len(data_list_ele)\n",
    "#trainev ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_ele[0].clusidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del data_list_comb\n",
    "totalevele = len(data_list_ele)\n",
    "ntrain = int(0.8*totalevele)\n",
    "import random\n",
    "\n",
    "\n",
    "#random.shuffle(data_list_ele)\n",
    "import torch_geometric\n",
    "ntrainbatch = 100\n",
    "ntestbatch = 100\n",
    "trainloader = torch_geometric.data.DataLoader(data_list_ele[:ntrain], batch_size=ntrainbatch,follow_batch=['x_clus'])\n",
    "testloader = torch_geometric.data.DataLoader(data_list_ele[ntrain:], batch_size=ntestbatch,follow_batch=['x_clus'])\n",
    "#batch_size = ntrainbatch\n",
    "epoch_size = len(data_list_ele[:ntrain])\n",
    "print(\"epoch size,batch_size:\",epoch_size,ntrainbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainloader:\n",
    "    print(data)\n",
    "    print(len(data.x_nodex))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "from torch_geometric.nn import EdgeConv, NNConv\n",
    "#from torch_geometric.nn.pool.edge_pool import EdgePooling\n",
    "\n",
    "from torch_geometric.utils import normalized_cut\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.utils.undirected import to_undirected\n",
    "from torch_geometric.nn import (graclus, max_pool, max_pool_x,\n",
    "                                global_mean_pool, global_max_pool,\n",
    "                                global_add_pool,BatchNorm)\n",
    "\n",
    "transform = T.Cartesian(cat=False)\n",
    "\n",
    "def normalized_cut_2d(edge_index, pos):\n",
    "    row, col = edge_index\n",
    "    edge_attr = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
    "    return normalized_cut(edge_index, edge_attr, num_nodes=pos.size(0))\n",
    "\n",
    "class ClusNetwork(nn.Module):\n",
    "    # Nodeclassification network \n",
    "    \n",
    "    def __init__(self, \n",
    "                 inputclus_dim=4,\n",
    "                 hiddenclus_dim=20,\n",
    "                 input_dim=64,\n",
    "                 hidden_dim=64,\n",
    "                 output_dim=1,\n",
    "                 clusk = 16,\n",
    "                 k=16, \n",
    "                 aggr='add',\n",
    "                 clusnorm=torch.tensor([1./500., 1./500., 1./54., 1/25., 1./1000.]),\n",
    "                 norm=torch.tensor([1./500., 1./500., 1./54., 1/25., 1./1000.])):\n",
    " #                norm=torch.tensor([1., 1., 1., 1., 1.])):\n",
    "        super(ClusNetwork, self).__init__()\n",
    "\n",
    "        self.datanorm = nn.Parameter(norm,requires_grad=False)\n",
    "        self.dataclusnorm = nn.Parameter(clusnorm,requires_grad=False)\n",
    "        \n",
    "        self.k = k\n",
    "        self.clusk = clusk\n",
    "        startclus_width = 2 * hiddenclus_dim\n",
    "        middleclus_width = 3 * hiddenclus_dim // 2\n",
    "        \n",
    "        start_width = 2 * hidden_dim\n",
    "        middle_width = 3 * hidden_dim // 2\n",
    "        \n",
    "        \n",
    "        self.clusinputnet =  nn.Sequential(\n",
    "            nn.Linear(inputclus_dim, hiddenclus_dim//2),            \n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hiddenclus_dim//2, hiddenclus_dim//2),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hiddenclus_dim//2, hiddenclus_dim),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.inputnet =  nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim//2),            \n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim//2),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        convnn1 = nn.Sequential(nn.Linear(startclus_width, middleclus_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(middleclus_width, hiddenclus_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        self.edgeconv1 = EdgeConv(nn=convnn1, aggr=aggr)\n",
    "        \n",
    "        convnn2 = nn.Sequential(nn.Linear(startclus_width, middleclus_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(middleclus_width, hiddenclus_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        self.edgeconv2 = EdgeConv(nn=convnn2, aggr=aggr)\n",
    "        \n",
    "        convnn3 = nn.Sequential(nn.Linear(startclus_width, middleclus_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(middleclus_width, hiddenclus_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        self.edgeconv3 = EdgeConv(nn=convnn3, aggr=aggr)\n",
    "        \n",
    "        \n",
    "        convnn4 = nn.Sequential(nn.Linear(startclus_width, middleclus_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(middleclus_width, hiddenclus_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        self.edgeconv4 = EdgeConv(nn=convnn4, aggr=aggr)\n",
    "        \n",
    "        convnn5 = nn.Sequential(nn.Linear(startclus_width, middleclus_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(middleclus_width, hiddenclus_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        self.edgeconv5 = EdgeConv(nn=convnn5, aggr=aggr)\n",
    "        \n",
    "        \n",
    "        convnn6 = nn.Sequential(nn.Linear(startclus_width, middleclus_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(middleclus_width, hiddenclus_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        self.edgeconv6 = EdgeConv(nn=convnn6, aggr=aggr)\n",
    "        \n",
    "        self.edge_classifier = nn.Sequential(\n",
    "            nn.Linear(2*hiddenclus_dim, hiddenclus_dim),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm1d(num_features=hiddenclus_dim),\n",
    "            nn.Linear(hiddenclus_dim, hiddenclus_dim//2),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm1d(num_features=hiddenclus_dim//2),\n",
    "            nn.Linear(hiddenclus_dim//2, output_dim)\n",
    "        )\n",
    "        \n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n",
    "                                    nn.ELU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    #nn.Softplus(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim//2),\n",
    "                                    nn.ELU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    #nn.Softplus(),\n",
    "#                                    nn.Linear(hidden_dim//2, hidden_dim//2),#added\n",
    " #                                   nn.ELU(),\n",
    "                                    #nn.Softplus(),\n",
    "                                    nn.Linear(hidden_dim//2, output_dim)\n",
    "                                   )\n",
    "        self.batchnorm1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        #getting the batch in batch indices\n",
    "        #print(data.x_clus_batch)\n",
    "        orig_edge_idx = data.edge_index_nodex.clone()\n",
    "        arrlist=[]\n",
    "        for i,j in enumerate(data.clusidx):\n",
    "            #print(i,j.numpy())\n",
    "            arrlist.append(np.full(j.detach().cpu().numpy(),i))\n",
    "        arrlist = np.concatenate(arrlist)\n",
    "        #batchinbatch = torch.tensor(arrlist,dtype=torch.int64,device=device)\n",
    "        batchinbatch = torch.tensor(arrlist,dtype=torch.int64).to(device) \n",
    "        #edgeconv for the clusters\n",
    "        data.x_clus = self.clusinputnet(data.x_clus)\n",
    "        edge_index = to_undirected(knn_graph(data.x_clus, self.clusk, batchinbatch, loop=False, flow=self.edgeconv1.flow))\n",
    "        data.x_clus = self.edgeconv1(data.x_clus, edge_index)\n",
    "        edge_index = to_undirected(knn_graph(data.x_clus, self.clusk, batchinbatch, loop=False, flow=self.edgeconv2.flow))\n",
    "        data.x_clus = self.edgeconv2(data.x_clus, edge_index)\n",
    "        edge_index = to_undirected(knn_graph(data.x_clus, self.clusk, batchinbatch, loop=False, flow=self.edgeconv3.flow))\n",
    "        data.x_clus = self.edgeconv3(data.x_clus, edge_index)\n",
    "        '''\n",
    "        print(\"batchinbatch\",batchinbatch)\n",
    "        print(\"data.batch\",data.batch)\n",
    "        \n",
    "        print(\"x_clus.shape\",x_clus.shape)\n",
    "        print(\"x_clus.batch\",batch)'''\n",
    "        \n",
    "        x_clus, batch = max_pool_x(batchinbatch, data.x_clus, data.x_clus_batch)\n",
    "        #print(\"x_clus.shape\",x_clus.shape)\n",
    "        #print(\"data.edge_index\",data.edge_index)\n",
    "        #print(\"data.edgelabel\",data.edgelabel.shape)\n",
    "        #print(\"data.nodex\",data.nodex.shape)\n",
    "        \n",
    "        #data.edge_index = to_undirected(knn_graph(x_clus, self.k, batch, loop=False, flow=self.edgeconv4.flow))\n",
    "        x_clus = self.edgeconv4(x_clus, orig_edge_idx)\n",
    "        #data.edge_index = to_undirected(knn_graph(x_clus, self.k, batch, loop=False, flow=self.edgeconv5.flow))\n",
    "        x_clus = self.edgeconv5(x_clus, orig_edge_idx)\n",
    "        \n",
    "        src, dst = orig_edge_idx\n",
    "        edge_scores = self.edge_classifier(torch.cat([x_clus[src], \n",
    "                                                      x_clus[dst]], \n",
    "                                                      dim=-1)).squeeze(-1)\n",
    "        \n",
    "        '''edge_scores = torch.cat([x_clus[src], \n",
    "                                x_clus[dst]], \n",
    "                                dim=-1)'''\n",
    "        \n",
    "        \n",
    "        \n",
    "        return edge_scores\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        '''src, dst = data.edge_index\n",
    "        #score = (data.x[src] * data.x[dst]).sum(dim=-1)\n",
    "        score = data.x[src] - data.x[dst]\n",
    "        return score.squeeze(-1)\n",
    "        \n",
    "        return 0'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_regulation import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.drn = ClusNetwork(inputclus_dim=4,\n",
    "                                           hiddenclus_dim=20, #50\n",
    "                                           k=6,#16\n",
    "                                           clusk = 16,\n",
    "                                           output_dim=2,\n",
    "                                           norm=torch.tensor([1., 1., 1., 1.,1.,1.,1.,1.]))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        logits = self.drn(data)\n",
    "        #return F.softplus(logits)\n",
    "        #return torch.sigmoid(logits)\n",
    "        return logits\n",
    "device = torch.device('cuda:1')#('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "model = Net().to(device)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
    "scheduler = CyclicLRWithRestarts(optimizer, ntrainbatch, epoch_size, restart_period=200, t_mult=1.2, policy=\"cosine\")\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum() \n",
    "\n",
    "focalloss = FocalLoss()        \n",
    "\n",
    "\n",
    "     \n",
    "#losscat = torch.nn.CrossEntropyLoss(weight=torch.tensor([1., 2.],device=\"cuda:1\"))    \n",
    "losscat = torch.nn.CrossEntropyLoss(weight=torch.tensor([1., 50.],device=\"cuda:1\"))    \n",
    "def categorical_loss(outputa,trutha,alpha):\n",
    "    total_loss =  losscat(outputa[:,:2],trutha[:,0].long()) + alpha*resoloss(outputa[:,2],trutha[:,1])\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def categorical_loss_only(outputa,trutha):\n",
    "    total_loss =  losscat(outputa,trutha) \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def bcategorical_loss(outputa,trutha):\n",
    "    total_loss = F.binary_cross_entropy(outputa, trutha.float())\n",
    "    return torch.mean(total_loss)\n",
    "\n",
    "#model.train()\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    #torch.cuda.empty_cache()\n",
    "    scheduler.step()\n",
    "    loss = []\n",
    "    for data in tqdm(trainloader):\n",
    "            data = data.to(device)        \n",
    "            optimizer.zero_grad()\n",
    "            #print(data.x.size())\n",
    "            #print(\"data.x\",data.x.shape)\n",
    "            #print(\"data.nodex\",data.nodex.shape)\n",
    "            result = model(data)\n",
    "            #print(\"result\",result)\n",
    "            #print(\"data.edgelabel\",data.edgelabel)\n",
    "            #print(result.shape,data.edgelabel.shape)\n",
    "            #lossc = focalloss(result, data.edgelabel.type(torch.int64))\n",
    "            lossc = categorical_loss_only(result, data.edgelabel.type(torch.int64))\n",
    "            #lossc = bcategorical_loss(result, data.edgelabel.type(torch.int64))\n",
    "            loss.append(lossc.item()) \n",
    "            lossc.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.batch_step()\n",
    "    print( 'batches for train:',len(loss)) \n",
    "#    print('loss',loss)\n",
    "    print('train loss:',np.mean(np.array(loss)))\n",
    "    return np.mean(np.array(loss))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian(x,  mean,a, sigma):\n",
    "    return a * np.exp(-((x - mean)**2 / (2 * sigma**2)))\n",
    "\n",
    "def evaluate(epoch):\n",
    "        \"\"\"\"Evaluate the model\"\"\"\n",
    "        model.zero_grad()\n",
    "        #torch.cuda.empty_cache()\n",
    "        model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        loss= []\n",
    "        \n",
    "        correct = 0\n",
    "        predc = []\n",
    "        truec = []\n",
    "        for data in tqdm(testloader):\n",
    "            data = data.to(device)        \n",
    "            result = model(data)\n",
    "            #lossc = resoloss(result, data.y)\n",
    "            #lossc = categorical_loss_only(result, data.label)\n",
    "            #lossc = focalloss(result, data.edgelabel.type(torch.int64))\n",
    "            lossc = categorical_loss_only(result, data.edgelabel.type(torch.int64))\n",
    "            #lossc = bcategorical_loss(result, data.edgelabel.type(torch.int64))\n",
    "#            print (result.item(),data.y.item())\n",
    "#            frac.append((result.item() - data.y.item())/data.y.item())\n",
    "            loss.append(lossc.item())\n",
    "\n",
    "            for i in result:\n",
    "                #pred.append(i.detach().cpu()[2])\n",
    "                #predc.append(i.detach().cpu())\n",
    "                predc.append(i.detach().cpu().argmax())\n",
    "            for i in data.edgelabel.detach():\n",
    "                #true.append(i.detach().cpu()[1])\n",
    "                truec.append(i.detach().cpu().flatten())\n",
    "                #print(i.detach().cpu())\n",
    "            \n",
    "        #print(predc,truec)\n",
    "        predc = np.array(predc)\n",
    "        #predc[predc < 0.5] = 0.\n",
    "        #predc[predc > 0.5] = 1.\n",
    "        truec = np.array(truec)\n",
    "        \n",
    "        #eleacc = [] \n",
    "        #puacc = []\n",
    "        \n",
    "        totacc = np.equal(predc,truec).sum()/len(truec)\n",
    "        eleacc = np.equal(predc[truec==1],truec[truec==1]).sum()/len(truec[truec==1])\n",
    "        puacc = np.equal(predc[truec==0],truec[truec==0]).sum()/len(truec[truec==0])\n",
    "\n",
    "\n",
    "        return np.mean(np.array(loss)), totacc, eleacc, puacc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "checkpoint_dir = '/home/llr/cms/sghosh/hackathonTICL/model_clusnetwork/'\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "best_loss = 99999999\n",
    "losst = []\n",
    "lossv = []\n",
    "epochs = []\n",
    "acc = []\n",
    "elc= []\n",
    "puc = []\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    print ('epoch:',epoch)\n",
    "    losst.append(train(epoch))\n",
    "    loss_epoch,accuracy, eleacc, puacc = evaluate(epoch)\n",
    "    lossv.append(loss_epoch)\n",
    "    acc.append(accuracy)\n",
    "    elc.append(eleacc)\n",
    "    puc.append(puacc)\n",
    "    epochs.append(epoch)\n",
    "    print(\"test total acc, ele acc, pu acc:\",accuracy,eleacc,puacc)\n",
    "    checkpoint = {\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    checkpoint_file = 'model_epoch_%i.pth.tar' % ( epoch )\n",
    "    torch.save(checkpoint,\n",
    "                   os.path.join(checkpoint_dir,checkpoint_file ))\n",
    "    if loss_epoch < best_loss:\n",
    "        best_loss = loss_epoch\n",
    "        print('new best test loss:',best_loss)\n",
    "        torch.save(checkpoint,\n",
    "                   os.path.join(checkpoint_dir,'model_checkpoint_best.pth.tar' ))\n",
    "    if (epoch%10 == 0):\n",
    "        plt.plot(np.array(epochs),np.array(losst),c='b',label='training')\n",
    "        plt.plot(np.array(epochs),np.array(lossv),c='r',label='testing')\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(checkpoint_dir+'loss_{0}.png'.format(epoch))\n",
    "        plt.show()\n",
    "        plt.plot(np.array(epochs),np.array(acc),c='b')\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.savefig(checkpoint_dir+'acc_class_{0}.png'.format(epoch))\n",
    "        plt.show()\n",
    "        fig, (ax0,ax1) = plt.subplots(1, 2, figsize=(20,12))\n",
    "        ax0.plot(np.array(epochs),np.array(elc))#,label=str(etabinsG[i])+\"_to_\"+str(etabinsG[i+1]))\n",
    "        ax1.set_xlabel(\"epoch\")\n",
    "        ax1.set_ylabel(\"accuracy ele\")\n",
    "        ax1.plot(np.array(epochs),np.array(puc))#,label=str(etabinsG[i])+\"_to_\"+str(etabinsG[i+1]))\n",
    "        ax1.set_xlabel(\"epoch\")\n",
    "        ax1.set_ylabel(\"accuracy pu\")\n",
    "        plt.legend()\n",
    "        plt.savefig(checkpoint_dir+'acc_class_feta_{0}.png'.format(epoch))\n",
    "        plt.show()   \n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtestgpu",
   "language": "python",
   "name": "torchtestgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
